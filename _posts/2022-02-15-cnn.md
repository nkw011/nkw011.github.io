---
title: "CNN"
excerpt: "convolution, stride, padding, pooling"
use_math: true
toc: true
toc_sticky: true
categories:
    - deeplearning
tags:
    - python
    - pytorch
    - deeplearning
    - ai
sidebar:
    nav: sidebarTotal
---

## 1. image 분류시 Multi Layer Perceptron(MLP)이 가지는 단점

image 분류시 문제점은 대상이 고정적인 위치에 있지 않다는 것이다.
예를 들어, 동물 dataset에서 고양이 사진을 분류한다고 해보자.
고양이는 사진의 어느 위치던지 존재할 수있다. 하지만, 어느 위치에 있던지 동일하게 고양이를 판별해야한다.

MLP를 대상의 위치가 고정적일 때 효과적인 분류 작업을 수행할 수있다. MNIST 숫자 분류를 해본다고 가정해보자 MLP는 중앙 위치에 존재하는 pixel의 변화를 탐지해서 숫자를 분류할 것이다. 만약 숫자가 중앙에 들어오지 않고 오른쪽 상단으로 들어오면 어떻게 될까? MLP는 중앙 위치의 존재하는 pixel들을 통해 학습을 하기 때문에 변화에 쉽게 대응할 수 없을 것이다.

이에 더해 MLP는 공간적인 정보를 담을 수 없다. 입력으로 들어오는 대상을 flatten(1차원)하게 변환시켜서 사용하기 때문에 공간 정보가 유실될 수 밖에 없다.

바로 이러한 문제점 때문에 CNN(Convolutional Neural Network)이 등장하게 되었다.

## 2. CNN (Convolutional Neural Network)

CNN은 kernel(filter)을 활용한 신경망이다. 입력으로 들어오는 image를 따로 형변환할 필요 없이 kernel을 이용해 공간적인 정보를 기억하면서 image가 가진 특징(feature)을 뽑아낸다.

### 2.1. 2D Convolution 연산

CNN은 Convolution 연산을 활용한다. kernel(filter)라는 $n \times m$ 행렬을 이용하여 image의 처음부터 끝까지 훑어서 계산한다.

예시를 통해 살펴보자.

<center><img width='600' height='307' src='/assets/image/cnn/cnn1.png'></center>

$4 \times 4$ image를 $3 \times 3$ kernel을 활용해 연산을 진행하는 과정이다.

#### 1st step

<center><img width='600' height='307' src='/assets/image/cnn/cnn2.png'></center>

#### 2nd step

<center><img width='600' height='307' src='/assets/image/cnn/cnn3.png'></center>

#### 3rd step

<center><img width='600' height='307' src='/assets/image/cnn/cnn4.png'></center>

#### 4th step

<center><img width='600' height='307' src='/assets/image/cnn/cnn5.png'></center>

#### Feature map

<center><img width='600' height='295' width='200' height='160' src='/assets/image/cnn/cnn6.png'></center>

Convolution 연산을 통해 나온 결과를 feature map(특성 맵)이라 한다.

#### stride

kernel의 이동 범위를 뜻한다. `stride=2`이면 kernel이 입력 이미지에서 2칸씩 이동한다는 뜻이다.
위의 예시에서는 kernel이 입력 이미지에 대해 1칸씩 이동하였으므로 `stride=1` 이다.

#### padding

입력 이미지 가장자리에 지정된 갯수만큼 행과 열을 추가하는 것이다.
예를 들어, `padding=1` 이면 입력 이미지 가장자리에 1칸씩 행과 열이 추가된다.

<center><img width='600' height='295' src='/assets/image/cnn/cnn7.png'></center>

주로 padding 값으로 '0'(zero padding)을 가장 많이 쓴다.
Convolution 연산 결과로 나오는 feature map의 크기를 어느 정도 유지하기 위해 사용된다.

### 2.2. Pooling 연산

Convolution 연산의 결과로 나온 feature map의 크기를 줄이는 연산을 뜻한다. 일반적으로 max pooling, average pooling이 많이 쓰인다.

Pooling 연산 또한 Convolution 연산과 같이 kernel의 개념을 가진다. kernel이 feature map의 처음부터 끝까지 이동하면서 연산을 수행한다.

-   Max Pooling: 주어진 범위 내에서 최댓값을 추출하는 연산
-   Max Pooling: 주어진 범위 내의 평균값을 추출하는 연산

<center><img width='600' height='244' src='/assets/image/cnn/cnn8.png'></center>

최근에는 Pooling을 사용하지 않고 Convolution 연산시 stride를 2 이상 설정해서 수행하는 경우도 있다.

### 2.3. 3차원 image에 대한 3D convolution 연산

보통 입력을 통해 들어오는 이미지는 3차원 tensor 형태를 지닌다. 그 이유는 색상이 R,G,B 3가지의 합으로 표현되기 때문이다. 따라서 너비와 높이 정보 이외의 색상의 정보를 담고 있는 채널이 같이 들어온다.

이를 tensor로 표현하면 다음과 같은 shape을 지닌다고 볼 수 있다.
$H: height, \, W: width, \, C: channel$ 라고 할 때, Convolution 입력을 통해 들어오는 이미지는 $(C,H,W)$ 또는 $(H,W,C)$의 형태를 지닌다.
보통 흑백 이미지인 gray-scale은 channel=1이고 컬러 이미지의 경우 red, green, blue가 모두 표현되어야 하기 때문에 channel=3이다.

3차원 tensor에 대한 convolution 연산을 3D convolution 연산이라고 지칭한다.
3D convoltuion 연산 역시 2D convolution 연산과 크게 다르지 않다. 단지, kernel도 입력 이미지와 같이 3차원 tensor가 되는 것이다.

먼저 입력 이미지의 shape을 $(C_{in}, H_i, W_i)$ 라고 해보자.
일단 이미지에 대한 kernel 연산을 수행해야하니 kerner의 채널도 입력 이미지의 채널 수만큼 존재해야할 것이다. 따라서 입력 이미지 1개에 대한 kernel의 채널 수도 똑같이 $C_{in}$가 될 것이다.

그렇다면 3D convolution 연산을 수행한 결과인 Feature map은 어떻게 될까? 일단 3차원 tensor를 받았으니 결과 역시 3차원 tensor로 나오게 된다. feature map도 channel 정보를 가진셈이 된다. 이 때 feature map의 채널 수는 어떻게 구해질까? 바로 kernel의 갯수가 feature map의 채널 수가 된다.

다시 정리하자면, 입력 이미지를 $(C_{in}, H, W)$ tensor라고 하고 kernel의 너비와 높이를 $H_k, \,W_k$라 할 때

-   kernel 또한 입력 이미지와 동일한 채널 수를 지닌다.
-   convolution의 연산 결과인 feature map 또한 채널 정보를 지닌 3차원 tensor가 되는데 feature map의 채널 수는 kernel의 갯수가 된다.

<center><img width='600' height='329' src='/assets/image/cnn/cnn9.png'></center>

## 3. CNN in PyTorch

### [torch.nn.CNN](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)

**Parameters**

-   in_channels: 입력 이미지 채널 수
-   out_channels: 출력 이미지 채널 수
-   kernel_size: 커널 크기
-   stride: stride 수
-   padding: padding 갯수
-   padding_mode: padding 형태. 'zeros' 등

**inputs**

-   $N$: batch, $C_{in}$: 입력 이미지 채널 수, $H_{in}$: 입력 이미지 높이, $W_{in}$: 입력 이미지 너비
-   $(N,C_{in},H_{in},W_{in})$

**outputs**

-   $N$: batch, $C_{out}$: feature map 채널 수, $H_{out}$: feature map 높이, $W_{out}$: feature map 너비
-   $(N, C_{out}, H_{out}, W_{out})$
